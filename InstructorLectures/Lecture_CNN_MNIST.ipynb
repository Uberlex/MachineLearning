{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "primary-netherlands",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.1.0\n",
      "Pandas version: 1.1.5\n",
      "Keras version: 2.2.4-tf\n",
      "Pillow version: 8.1.0 \n",
      "\n",
      "GPU's: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Import tensorflow.\n",
    "import tensorflow as tf\n",
    "\n",
    "# PIL (Pillow) for working with images.\n",
    "import PIL\n",
    "from PIL import Image , ImageOps\n",
    "\n",
    "# Used for globbing up directories.\n",
    "import glob\n",
    "\n",
    "# The Data Tools \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the Keras tools.\n",
    "from tensorflow import keras\n",
    "\n",
    "# Network type.\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Layer information.\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# For editing images. \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "print(\"Pillow version:\",PIL.__version__,\"\\n\")\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "print(\"GPU's:\",physical_devices)\n",
    "for gpu_instance in physical_devices: \n",
    "    tf.config.experimental.set_memory_growth(gpu_instance, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-earthquake",
   "metadata": {},
   "source": [
    "## **Image Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-authority",
   "metadata": {},
   "source": [
    "Set the path the the images. This need to be structured as classes are in directories together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brief-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path_train = \"../Data/mnist_images/trainingSet/trainingSet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-services",
   "metadata": {},
   "source": [
    "The ImageDataGenerator allows us to modify the images to increase the size of the data set. This will be useful if we don't have enough labeled images but we sill want to train the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "military-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "        rescale = 1 / 255.0,\n",
    "        #rotation_range=20,\n",
    "        #zoom_range=5,\n",
    "        #width_shift_range=5,\n",
    "        #height_shift_range=5,\n",
    "        #shear_range=100,\n",
    "        horizontal_flip=True,\n",
    "        #fill_mode=\"nearest\",\n",
    "        validation_split=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-maintenance",
   "metadata": {},
   "source": [
    "In the next cell we are going to setup the data flow pipeline using flow_from_directory. This tool allows us to use Keras to feed the images from the directories into the network. It will also allow us to set a batch size as well as a few other setting for the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "injured-society",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33607 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory=src_path_train,\n",
    "    target_size=(28, 28),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-phone",
   "metadata": {},
   "source": [
    "## **Check a few Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "suspected-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "\n",
    "for images,labels in next(zip(train_generator)):\n",
    "    for i in range(10): # can't be greater than 20\n",
    "        image_list.append(images[i])\n",
    "\n",
    "plt.matshow(image_list[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "known-vatican",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 28, 28, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-border",
   "metadata": {},
   "source": [
    "## **The Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "treated-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(5,5),activation='relu',input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "'''\n",
    "model.add(Conv2D(128, kernel_size=(5,5),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(512, kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "'''\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(300, activation='relu'))\n",
    "#model.add(Dropout(.5))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "          \n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "comic-walter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        1664      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               2765100   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 2,848,074\n",
      "Trainable params: 2,848,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-above",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "analyzed-spanish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 336 steps\n",
      "Epoch 1/3\n",
      "336/336 [==============================] - 6s 19ms/step - loss: 0.3703 - accuracy: 0.8782\n",
      "Epoch 2/3\n",
      "336/336 [==============================] - 6s 19ms/step - loss: 0.1212 - accuracy: 0.9620\n",
      "Epoch 3/3\n",
      "336/336 [==============================] - 7s 20ms/step - loss: 0.0828 - accuracy: 0.9736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f54c2ac5a90>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, steps_per_epoch = train_generator.n//train_generator.batch_size, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-needle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-times",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
